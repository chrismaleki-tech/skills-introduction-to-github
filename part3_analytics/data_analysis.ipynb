{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 3: Data Analytics - Rearc Data Quest\n",
        "\n",
        "This notebook performs comprehensive data analysis on the BLS time-series data and population data collected in Parts 1 and 2.\n",
        "\n",
        "## Analysis Objectives\n",
        "\n",
        "1. **Population Statistics (2013-2018)**: Calculate mean and standard deviation of annual US population\n",
        "2. **BLS Time-Series Analysis**: Find the best year for each series_id (max sum of quarterly values)\n",
        "3. **Combined Analysis**: Join BLS and population data for series_id PRS30006032, period Q01\n",
        "\n",
        "## Data Sources\n",
        "\n",
        "- **BLS Dataset**: Bureau of Labor Statistics time-series data (Part 1)\n",
        "- **Population Data**: DataUSA API population data (Part 2)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import boto3\n",
        "import json\n",
        "import io\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"\u2705 Libraries imported successfully\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "BLS_BUCKET_NAME = 'rearc-quest-bls-data'\n",
        "POPULATION_BUCKET_NAME = 'rearc-quest-population-data'\n",
        "\n",
        "# Initialize S3 client\n",
        "s3_client = boto3.client('s3')\n",
        "\n",
        "def load_data_from_s3(bucket_name, key):\n",
        "    \"\"\"Load data from S3 bucket\"\"\"\n",
        "    try:\n",
        "        response = s3_client.get_object(Bucket=bucket_name, Key=key)\n",
        "        return response['Body'].read()\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {key} from {bucket_name}: {e}\")\n",
        "        return None\n",
        "\n",
        "def load_csv_from_s3(bucket_name, key):\n",
        "    \"\"\"Load CSV data from S3 into pandas DataFrame\"\"\"\n",
        "    data = load_data_from_s3(bucket_name, key)\n",
        "    if data:\n",
        "        return pd.read_csv(io.BytesIO(data))\n",
        "    return None\n",
        "\n",
        "def load_json_from_s3(bucket_name, key):\n",
        "    \"\"\"Load JSON data from S3\"\"\"\n",
        "    data = load_data_from_s3(bucket_name, key)\n",
        "    if data:\n",
        "        return json.loads(data.decode('utf-8'))\n",
        "    return None\n",
        "\n",
        "print(\"\u2705 S3 utilities configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Population Data from S3\n",
        "\n",
        "Loading the population data fetched from DataUSA API in Part 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load population data for years 2013-2018\n",
        "population_json = load_json_from_s3(POPULATION_BUCKET_NAME, 'population-data/population_data_2013_2018.json')\n",
        "\n",
        "if population_json and 'data' in population_json:\n",
        "    # Convert to DataFrame\n",
        "    population_df = pd.DataFrame(population_json['data'])\n",
        "    \n",
        "    # Data cleaning and preprocessing\n",
        "    population_df['Year'] = population_df['Year'].astype(int)\n",
        "    population_df['Population'] = population_df['Population'].astype(int)\n",
        "    \n",
        "    # Sort by year\n",
        "    population_df = population_df.sort_values('Year').reset_index(drop=True)\n",
        "    \n",
        "    print(\"\u2705 Population data loaded successfully\")\n",
        "    print(f\"Data shape: {population_df.shape}\")\n",
        "    print(f\"Years available: {sorted(population_df['Year'].unique())}\")\n",
        "    print(\"\\nFirst 5 rows:\")\n",
        "    display(population_df.head())\n",
        "    \n",
        "    # Basic statistics\n",
        "    print(f\"\\nPopulation range: {population_df['Population'].min():,} to {population_df['Population'].max():,}\")\n",
        "    \n",
        "else:\n",
        "    print(\"\u274c Failed to load population data\")\n",
        "    population_df = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load BLS Time-Series Data from S3\n",
        "\n",
        "Loading the BLS time-series data (pr.data.0.Current) from Part 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load BLS time-series data\n",
        "bls_df = load_csv_from_s3(BLS_BUCKET_NAME, 'bls-data/pr.data.0.Current')\n",
        "\n",
        "if bls_df is not None:\n",
        "    print(\"\u2705 BLS time-series data loaded successfully\")\n",
        "    print(f\"Data shape: {bls_df.shape}\")\n",
        "    print(f\"Columns: {list(bls_df.columns)}\")\n",
        "    \n",
        "    # Display first few rows\n",
        "    print(\"\\nFirst 5 rows:\")\n",
        "    display(bls_df.head())\n",
        "    \n",
        "    # Data cleaning and preprocessing\n",
        "    # Remove any whitespace from string columns\n",
        "    for col in bls_df.select_dtypes(include=['object']).columns:\n",
        "        bls_df[col] = bls_df[col].astype(str).str.strip()\n",
        "    \n",
        "    # Convert year to int if it's not already\n",
        "    if 'year' in bls_df.columns:\n",
        "        bls_df['year'] = pd.to_numeric(bls_df['year'], errors='coerce')\n",
        "    \n",
        "    # Convert value to numeric\n",
        "    if 'value' in bls_df.columns:\n",
        "        bls_df['value'] = pd.to_numeric(bls_df['value'], errors='coerce')\n",
        "    \n",
        "    print(f\"\\nData types after cleaning:\")\n",
        "    print(bls_df.dtypes)\n",
        "    \n",
        "    print(f\"\\nUnique series_id count: {bls_df['series_id'].nunique()}\")\n",
        "    print(f\"Year range: {bls_df['year'].min()} to {bls_df['year'].max()}\")\n",
        "    print(f\"Unique periods: {sorted(bls_df['period'].unique())}\")\n",
        "    \n",
        "    # Check for missing values\n",
        "    print(f\"\\nMissing values:\")\n",
        "    print(bls_df.isnull().sum())\n",
        "    \n",
        "else:\n",
        "    print(\"\u274c Failed to load BLS data\")\n",
        "    bls_df = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis 1: US Population Statistics (2013-2018)\n",
        "\n",
        "Calculate mean and standard deviation of US population for the specified period."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analysis 1: Calculate mean and standard deviation of US population (2013-2018)\n",
        "if not population_df.empty:\n",
        "    # Filter data for years 2013-2018 (should already be filtered, but being explicit)\n",
        "    analysis_df = population_df[(population_df['Year'] >= 2013) & (population_df['Year'] <= 2018)].copy()\n",
        "    \n",
        "    # Calculate statistics\n",
        "    mean_population = analysis_df['Population'].mean()\n",
        "    std_population = analysis_df['Population'].std()\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"ANALYSIS 1: US POPULATION STATISTICS (2013-2018)\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Mean Population: {mean_population:,.0f}\")\n",
        "    print(f\"Standard Deviation: {std_population:,.0f}\")\n",
        "    print(f\"Coefficient of Variation: {(std_population/mean_population)*100:.2f}%\")\n",
        "    \n",
        "    # Create visualization\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    \n",
        "    # Population trend\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(analysis_df['Year'], analysis_df['Population'], marker='o', linewidth=2, markersize=8)\n",
        "    plt.axhline(y=mean_population, color='red', linestyle='--', alpha=0.7, label=f'Mean: {mean_population:,.0f}')\n",
        "    plt.fill_between(analysis_df['Year'], \n",
        "                     mean_population - std_population, \n",
        "                     mean_population + std_population, \n",
        "                     alpha=0.2, color='red', label=f'\u00b11 Std Dev')\n",
        "    plt.title('US Population Trend (2013-2018)')\n",
        "    plt.xlabel('Year')\n",
        "    plt.ylabel('Population')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Statistics summary\n",
        "    plt.subplot(1, 2, 2)\n",
        "    stats_data = [mean_population, std_population]\n",
        "    stats_labels = ['Mean', 'Std Dev']\n",
        "    colors = ['skyblue', 'lightcoral']\n",
        "    bars = plt.bar(stats_labels, stats_data, color=colors, alpha=0.7)\n",
        "    plt.title('Population Statistics Summary')\n",
        "    plt.ylabel('Population')\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar, value in zip(bars, stats_data):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + value*0.01,\n",
        "                f'{value:,.0f}', ha='center', va='bottom')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Store results for later use\n",
        "    population_stats = {\n",
        "        'mean': mean_population,\n",
        "        'std': std_population,\n",
        "        'years': list(analysis_df['Year']),\n",
        "        'populations': list(analysis_df['Population'])\n",
        "    }\n",
        "    \n",
        "else:\n",
        "    print(\"\u274c Cannot perform population analysis - no data available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis 2: Best Year for Each BLS Series\n",
        "\n",
        "Find the year with the maximum sum of quarterly values for each series_id."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analysis 2: Find the best year for each series_id\n",
        "if not bls_df.empty:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ANALYSIS 2: BEST YEAR FOR EACH SERIES_ID\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Filter for quarterly data only (Q01, Q02, Q03, Q04)\n",
        "    quarterly_df = bls_df[bls_df['period'].isin(['Q01', 'Q02', 'Q03', 'Q04'])].copy()\n",
        "    \n",
        "    # Remove rows with missing values\n",
        "    quarterly_df = quarterly_df.dropna(subset=['series_id', 'year', 'value'])\n",
        "    \n",
        "    print(f\"Working with {len(quarterly_df)} quarterly records\")\n",
        "    print(f\"Series IDs: {quarterly_df['series_id'].nunique()}\")\n",
        "    print(f\"Year range: {quarterly_df['year'].min()} to {quarterly_df['year'].max()}\")\n",
        "    \n",
        "    # Group by series_id and year, sum the quarterly values\n",
        "    yearly_sums = quarterly_df.groupby(['series_id', 'year'])['value'].sum().reset_index()\n",
        "    yearly_sums.columns = ['series_id', 'year', 'annual_sum']\n",
        "    \n",
        "    # Find the best year (max sum) for each series_id\n",
        "    best_years = yearly_sums.loc[yearly_sums.groupby('series_id')['annual_sum'].idxmax()]\n",
        "    best_years = best_years.rename(columns={'annual_sum': 'value'})\n",
        "    \n",
        "    print(f\"\\nBest Year Analysis Results:\")\n",
        "    print(f\"Number of series analyzed: {len(best_years)}\")\n",
        "    \n",
        "    # Display top 10 results\n",
        "    print(f\"\\nTop 10 series by best year value:\")\n",
        "    display(best_years.nlargest(10, 'value')[['series_id', 'year', 'value']])\n",
        "    \n",
        "    # Summary statistics\n",
        "    print(f\"\\nSummary Statistics:\")\n",
        "    print(f\"Best years range: {best_years['year'].min()} to {best_years['year'].max()}\")\n",
        "    print(f\"Average best year value: {best_years['value'].mean():.2f}\")\n",
        "    print(f\"Median best year value: {best_years['value'].median():.2f}\")\n",
        "    \n",
        "    # Year distribution\n",
        "    year_counts = best_years['year'].value_counts().sort_index()\n",
        "    print(f\"\\nDistribution of best years:\")\n",
        "    for year, count in year_counts.items():\n",
        "        print(f\"  {year}: {count} series\")\n",
        "    \n",
        "    # Visualization\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    \n",
        "    # Best year distribution\n",
        "    plt.subplot(2, 2, 1)\n",
        "    year_counts.plot(kind='bar', color='skyblue', alpha=0.7)\n",
        "    plt.title('Distribution of Best Years Across Series')\n",
        "    plt.xlabel('Year')\n",
        "    plt.ylabel('Number of Series')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Value distribution\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.hist(best_years['value'], bins=20, color='lightcoral', alpha=0.7, edgecolor='black')\n",
        "    plt.title('Distribution of Best Year Values')\n",
        "    plt.xlabel('Value')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Top series by value\n",
        "    plt.subplot(2, 2, 3)\n",
        "    top_series = best_years.nlargest(10, 'value')\n",
        "    plt.barh(range(len(top_series)), top_series['value'], color='lightgreen', alpha=0.7)\n",
        "    plt.yticks(range(len(top_series)), [f\"{sid}\\n({year})\" for sid, year in zip(top_series['series_id'], top_series['year'])])\n",
        "    plt.title('Top 10 Series by Best Year Value')\n",
        "    plt.xlabel('Value')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Example time series for one series\n",
        "    plt.subplot(2, 2, 4)\n",
        "    example_series = best_years.iloc[0]['series_id']\n",
        "    example_data = quarterly_df[quarterly_df['series_id'] == example_series]\n",
        "    example_yearly = example_data.groupby('year')['value'].sum()\n",
        "    \n",
        "    plt.plot(example_yearly.index, example_yearly.values, marker='o', linewidth=2)\n",
        "    best_year = best_years[best_years['series_id'] == example_series]['year'].iloc[0]\n",
        "    best_value = best_years[best_years['series_id'] == example_series]['value'].iloc[0]\n",
        "    plt.axvline(x=best_year, color='red', linestyle='--', alpha=0.7)\n",
        "    plt.scatter([best_year], [best_value], color='red', s=100, zorder=5)\n",
        "    plt.title(f'Example: {example_series}\\nBest Year: {best_year}')\n",
        "    plt.xlabel('Year')\n",
        "    plt.ylabel('Annual Sum')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Save the complete results\n",
        "    print(f\"\\nComplete Best Year Analysis Report:\")\n",
        "    display(best_years.sort_values('value', ascending=False))\n",
        "    \n",
        "else:\n",
        "    print(\"\u274c Cannot perform BLS analysis - no data available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis 3: Combined BLS and Population Data\n",
        "\n",
        "Joining BLS time-series data for series_id = PRS30006032, period = Q01 with population data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analysis 3: Combined BLS and Population Analysis\n",
        "if not bls_df.empty and not population_df.empty:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ANALYSIS 3: COMBINED BLS AND POPULATION DATA\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Filter BLS data for specific series and period\n",
        "    target_series = 'PRS30006032'\n",
        "    target_period = 'Q01'\n",
        "    \n",
        "    # Filter BLS data\n",
        "    filtered_bls = bls_df[\n",
        "        (bls_df['series_id'].str.strip() == target_series) & \n",
        "        (bls_df['period'].str.strip() == target_period)\n",
        "    ].copy()\n",
        "    \n",
        "    print(f\"BLS data for series {target_series}, period {target_period}:\")\n",
        "    print(f\"Records found: {len(filtered_bls)}\")\n",
        "    \n",
        "    if len(filtered_bls) > 0:\n",
        "        # Ensure year columns are compatible for merging\n",
        "        filtered_bls['year'] = filtered_bls['year'].astype(int)\n",
        "        population_df['Year'] = population_df['Year'].astype(int)\n",
        "        \n",
        "        # Merge BLS data with population data\n",
        "        merged_df = filtered_bls.merge(\n",
        "            population_df[['Year', 'Population']], \n",
        "            left_on='year', \n",
        "            right_on='Year', \n",
        "            how='inner'\n",
        "        )\n",
        "        \n",
        "        # Select and rename columns for final report\n",
        "        final_report = merged_df[['series_id', 'year', 'period', 'value', 'Population']].copy()\n",
        "        final_report = final_report.rename(columns={'year': 'year'})\n",
        "        \n",
        "        print(f\"\\nMerged data shape: {final_report.shape}\")\n",
        "        print(f\"Year range in merged data: {final_report['year'].min()} to {final_report['year'].max()}\")\n",
        "        \n",
        "        # Display the complete report\n",
        "        print(f\"\\nCOMPLETE COMBINED ANALYSIS REPORT:\")\n",
        "        print(\"=\" * 50)\n",
        "        display(final_report.sort_values('year'))\n",
        "        \n",
        "        # Create visualization\n",
        "        plt.figure(figsize=(15, 8))\n",
        "        \n",
        "        # BLS values over time\n",
        "        plt.subplot(2, 2, 1)\n",
        "        plt.plot(final_report['year'], final_report['value'], marker='o', linewidth=2, color='blue')\n",
        "        plt.title(f'BLS Series {target_series} (Q01) Over Time')\n",
        "        plt.xlabel('Year')\n",
        "        plt.ylabel('BLS Value')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Population over time\n",
        "        plt.subplot(2, 2, 2)\n",
        "        plt.plot(final_report['year'], final_report['Population'], marker='s', linewidth=2, color='red')\n",
        "        plt.title('US Population Over Time')\n",
        "        plt.xlabel('Year')\n",
        "        plt.ylabel('Population')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Dual axis plot\n",
        "        plt.subplot(2, 1, 2)\n",
        "        ax1 = plt.gca()\n",
        "        ax2 = ax1.twinx()\n",
        "        \n",
        "        line1 = ax1.plot(final_report['year'], final_report['value'], marker='o', linewidth=2, color='blue', label=f'BLS {target_series} (Q01)')\n",
        "        line2 = ax2.plot(final_report['year'], final_report['Population'], marker='s', linewidth=2, color='red', label='Population')\n",
        "        \n",
        "        ax1.set_xlabel('Year')\n",
        "        ax1.set_ylabel('BLS Value', color='blue')\n",
        "        ax2.set_ylabel('Population', color='red')\n",
        "        ax1.tick_params(axis='y', labelcolor='blue')\n",
        "        ax2.tick_params(axis='y', labelcolor='red')\n",
        "        \n",
        "        # Combine legends\n",
        "        lines = line1 + line2\n",
        "        labels = [l.get_label() for l in lines]\n",
        "        ax1.legend(lines, labels, loc='upper left')\n",
        "        \n",
        "        plt.title(f'Combined Analysis: BLS Series {target_series} vs US Population')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Calculate correlation\n",
        "        correlation = final_report['value'].corr(final_report['Population'])\n",
        "        print(f\"\\nCorrelation between BLS value and Population: {correlation:.4f}\")\n",
        "        \n",
        "        # Summary statistics\n",
        "        print(f\"\\nSummary Statistics:\")\n",
        "        print(f\"BLS Value - Mean: {final_report['value'].mean():.2f}, Std: {final_report['value'].std():.2f}\")\n",
        "        print(f\"Population - Mean: {final_report['Population'].mean():,.0f}, Std: {final_report['Population'].std():,.0f}\")\n",
        "        \n",
        "        # Example row format as requested\n",
        "        print(f\"\\nExample row (as requested in requirements):\")\n",
        "        if len(final_report) > 0:\n",
        "            example_row = final_report.iloc[0]\n",
        "            print(f\"series_id: {example_row['series_id']}\")\n",
        "            print(f\"year: {example_row['year']}\")\n",
        "            print(f\"period: {example_row['period']}\")\n",
        "            print(f\"value: {example_row['value']}\")\n",
        "            print(f\"Population: {example_row['Population']}\")\n",
        "        \n",
        "    else:\n",
        "        print(f\"\u274c No data found for series {target_series} with period {target_period}\")\n",
        "        \n",
        "        # Show available series and periods for debugging\n",
        "        print(f\"\\nAvailable series_id values (first 10):\")\n",
        "        print(bls_df['series_id'].str.strip().unique()[:10])\n",
        "        print(f\"\\nAvailable period values:\")\n",
        "        print(bls_df['period'].str.strip().unique())\n",
        "        \n",
        "else:\n",
        "    print(\"\u274c Cannot perform combined analysis - missing BLS or population data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Conclusions\n",
        "\n",
        "### Key Findings\n",
        "\n",
        "1. **Population Analysis (2013-2018)**\n",
        "   - Mean US population calculated for the specified period\n",
        "   - Standard deviation showing population growth trend\n",
        "   - Year-over-year growth patterns visualized\n",
        "\n",
        "2. **BLS Time-Series Analysis**\n",
        "   - Best performing year identified for each series_id\n",
        "   - Quarterly data aggregated to annual sums\n",
        "   - Distribution of peak performance years across different economic indicators\n",
        "\n",
        "3. **Combined Dataset Insights**\n",
        "   - Correlation analysis between economic indicators and population\n",
        "   - Temporal alignment of BLS productivity data with demographic trends\n",
        "   - Data quality assessment and cleaning procedures documented\n",
        "\n",
        "### Data Quality Notes\n",
        "\n",
        "- All string fields trimmed of whitespace before analysis\n",
        "- Missing values handled appropriately for each analysis type\n",
        "- Data type conversions validated for numerical operations\n",
        "- Cross-dataset joins performed on cleaned, validated year fields\n",
        "\n",
        "### Technical Implementation\n",
        "\n",
        "- Efficient S3 data loading with error handling\n",
        "- Pandas operations optimized for large datasets\n",
        "- Comprehensive visualization suite for all analyses\n",
        "- Reproducible analysis with clear documentation\n",
        "\n",
        "---\n",
        "\n",
        "**Analysis completed successfully** \u2705"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}