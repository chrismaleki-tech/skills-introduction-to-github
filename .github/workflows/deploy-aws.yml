name: Deploy to AWS

on:
  push:
    branches: [ main, develop, 'cursor/**' ]  # Include cursor branches for development
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'dev'
        type: choice
        options:
        - dev
        - staging
        - prod
      aws-region:
        description: 'AWS Region to deploy to'
        required: true
        default: 'us-east-2'
        type: string
      trigger-e2e-pipeline:
        description: 'Trigger end-to-end pipeline after deployment'
        required: false
        default: false
        type: boolean

env:
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  AWS_DEFAULT_REGION: ${{ github.event.inputs.aws-region || secrets.AWS_DEFAULT_REGION || 'us-east-2' }}
  CDK_DEFAULT_REGION: ${{ github.event.inputs.aws-region || secrets.AWS_DEFAULT_REGION || 'us-east-2' }}
  PYTHON_VERSION: '3.9'
  NODE_VERSION: '18'

jobs:
  deploy-infrastructure:
    name: Deploy AWS Infrastructure
    runs-on: ubuntu-latest
    # Updated condition to include cursor branches for development
    if: github.ref == 'refs/heads/main' || contains(github.ref, 'cursor/') || github.event_name == 'workflow_dispatch'
    environment: 
      name: ${{ github.event.inputs.environment || 'dev' }}
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ env.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}

      - name: Verify AWS Credentials
        run: |
          aws sts get-caller-identity
          aws s3 ls || echo "No S3 buckets found"

      - name: Cache Python Dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}

      - name: Install Python Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r part4_infrastructure/cdk/requirements.txt

      - name: Install AWS CDK
        run: |
          npm install -g aws-cdk@latest
          cdk --version

      - name: Build Lambda Packages
        run: |
          cd part4_infrastructure/lambda_functions
          
          # Ensure we have the necessary files
          if [ ! -f "build_minimal_package.sh" ]; then
            echo "ERROR: build_minimal_package.sh not found!"
            exit 1
          fi
          
          # Make build scripts executable
          chmod +x build_minimal_package.sh
          chmod +x build_lambda_package.sh
          chmod +x build_analytics_package.sh
          
          # Build the minimal package required by CDK
          echo "Building minimal Lambda package..."
          ./build_minimal_package.sh
          
          # Verify the package was created
          if [ ! -f "build-minimal/lambda-minimal-package.zip" ]; then
            echo "ERROR: lambda-minimal-package.zip was not created!"
            ls -la build-minimal/ || echo "build-minimal directory does not exist"
            exit 1
          fi
          
          echo "âœ… Lambda packages built successfully"
          echo "Package size: $(du -h build-minimal/lambda-minimal-package.zip | cut -f1)"
          ls -la build-minimal/

      - name: Bootstrap CDK (if needed)
        run: |
          cd part4_infrastructure/cdk
          # Get AWS account ID dynamically if not provided in secrets
          ACCOUNT_ID="${{ secrets.CDK_DEFAULT_ACCOUNT }}"
          if [ -z "$ACCOUNT_ID" ]; then
            ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          fi
          cdk bootstrap aws://$ACCOUNT_ID/${{ env.AWS_DEFAULT_REGION }}
        continue-on-error: true

      - name: CDK Synth
        run: |
          cd part4_infrastructure/cdk
          cdk synth

      - name: CDK Diff
        run: |
          cd part4_infrastructure/cdk
          cdk diff || echo "No differences found or first deployment"

      - name: Check Stack Status and Handle Rollback Failed
        run: |
          cd part4_infrastructure/cdk
          
          # Check if stack exists and its status
          STACK_STATUS=$(aws cloudformation describe-stacks --stack-name RearcDataQuestPipeline --query 'Stacks[0].StackStatus' --output text 2>/dev/null || echo "STACK_NOT_FOUND")
          
          echo "Current stack status: $STACK_STATUS"
          
          if [ "$STACK_STATUS" = "UPDATE_ROLLBACK_FAILED" ]; then
            echo "âš ï¸  Stack is in UPDATE_ROLLBACK_FAILED state. Attempting to recover..."
            
            # Try to continue rollback first
            if aws cloudformation continue-update-rollback --stack-name RearcDataQuestPipeline; then
              echo "âœ… Continue rollback initiated successfully"
              
              # Wait for rollback to complete
              echo "â³ Waiting for rollback to complete..."
              aws cloudformation wait stack-update-rollback-complete --stack-name RearcDataQuestPipeline || {
                echo "âš ï¸  Rollback did not complete successfully. Checking for stuck resources..."
                
                # Get stuck resources and try to skip them
                STUCK_RESOURCES=$(aws cloudformation describe-stack-resources --stack-name RearcDataQuestPipeline --query 'StackResources[?ResourceStatus==`UPDATE_FAILED` || ResourceStatus==`DELETE_FAILED`].LogicalResourceId' --output text)
                
                if [ -n "$STUCK_RESOURCES" ]; then
                  echo "Found stuck resources: $STUCK_RESOURCES"
                  echo "Attempting to continue rollback with skipped resources..."
                  aws cloudformation continue-update-rollback --stack-name RearcDataQuestPipeline --resources-to-skip $STUCK_RESOURCES
                  aws cloudformation wait stack-update-rollback-complete --stack-name RearcDataQuestPipeline
                fi
              }
            else
              echo "âŒ Failed to continue rollback. Manual intervention may be required."
              exit 1
            fi
          elif [ "$STACK_STATUS" = "ROLLBACK_IN_PROGRESS" ]; then
            echo "â³ Stack rollback already in progress. Waiting for completion..."
            aws cloudformation wait stack-update-rollback-complete --stack-name RearcDataQuestPipeline
          elif [ "$STACK_STATUS" = "UPDATE_IN_PROGRESS" ]; then
            echo "â³ Stack update in progress. Waiting for completion..."
            aws cloudformation wait stack-update-complete --stack-name RearcDataQuestPipeline || {
              echo "âš ï¸  Update failed. Checking final status..."
              FINAL_STATUS=$(aws cloudformation describe-stacks --stack-name RearcDataQuestPipeline --query 'Stacks[0].StackStatus' --output text)
              if [ "$FINAL_STATUS" = "UPDATE_ROLLBACK_FAILED" ]; then
                echo "âŒ Stack is now in UPDATE_ROLLBACK_FAILED state. Re-run this workflow to recover."
                exit 1
              fi
            }
          fi
          
          echo "âœ… Stack is ready for deployment"
        timeout-minutes: 15

      - name: Deploy CDK Stack
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION }}
        run: |
          cd part4_infrastructure/cdk

          # Set CDK environment variables
          export CDK_DEFAULT_ACCOUNT=$(aws sts get-caller-identity --query Account --output text)
          export CDK_DEFAULT_REGION=$AWS_DEFAULT_REGION

          echo "Deploying CDK stack..."
          cdk deploy --require-approval never --verbose
        timeout-minutes: 30

      - name: Save CDK Outputs
        run: |
          cd part4_infrastructure/cdk
          cdk deploy --outputs-file cdk-outputs.json --require-approval never || echo "Stack already deployed"

      - name: Upload CDK Outputs
        uses: actions/upload-artifact@v4
        with:
          name: cdk-outputs
          path: part4_infrastructure/cdk/cdk-outputs.json

  deploy-applications:
    name: Deploy Applications & Functions
    runs-on: ubuntu-latest
    needs: [deploy-infrastructure]
    if: github.ref == 'refs/heads/main' || contains(github.ref, 'cursor/') || github.event_name == 'workflow_dispatch'
    environment: 
      name: ${{ github.event.inputs.environment || 'dev' }}

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ env.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Download CDK Outputs
        uses: actions/download-artifact@v4
        with:
          name: cdk-outputs
          path: ./artifacts

      - name: Run Data Sourcing Script
        run: |
          cd part1_data_sourcing
          python bls_data_sync.py
        continue-on-error: true

      - name: Run API Integration
        run: |
          cd part2_api_integration
          python population_api.py
        continue-on-error: true

      - name: Test Lambda Functions
        run: |
          # Test if Lambda functions are deployed and accessible
          aws lambda list-functions --query 'Functions[?contains(FunctionName, `rearc`) || contains(FunctionName, `RearcDataQuest`)].FunctionName' --output table

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [deploy-applications]
    if: github.ref == 'refs/heads/main' || contains(github.ref, 'cursor/') || github.event_name == 'workflow_dispatch'
    environment: 
      name: ${{ github.event.inputs.environment || 'dev' }}

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ env.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}

      - name: Test S3 Buckets
        run: |
          echo "Testing S3 bucket access..."
          aws s3 ls s3://rearc-quest-bls-data/ || echo "BLS bucket not found or empty"
          aws s3 ls s3://rearc-quest-population-data/ || echo "Population bucket not found or empty"

      - name: Test SQS Queues
        run: |
          echo "Testing SQS queues..."
          aws sqs list-queues --query 'QueueUrls[?contains(@, `rearc`) || contains(@, `RearcDataQuest`)]' --output table

      - name: Test Lambda Functions
        run: |
          echo "Testing Lambda functions..."
          # Create test payload file
          echo '{"test": true}' > /tmp/test-payload.json
          for func in $(aws lambda list-functions --query 'Functions[?contains(FunctionName, `rearc`) || contains(FunctionName, `RearcDataQuest`)].FunctionName' --output text); do
            echo "Testing function: $func"
            aws lambda invoke --function-name "$func" --payload file:///tmp/test-payload.json /tmp/response.json || echo "Function invocation failed for $func"
          done

      - name: Generate Deployment Report
        run: |
          echo "# Deployment Report" > deployment-report.md
          echo "## Date: $(date)" >> deployment-report.md
          echo "## Region: $AWS_DEFAULT_REGION" >> deployment-report.md
          echo "## S3 Buckets:" >> deployment-report.md
          aws s3 ls | grep rearc >> deployment-report.md || echo "No rearc buckets found" >> deployment-report.md
          echo "## Lambda Functions:" >> deployment-report.md
          aws lambda list-functions --query 'Functions[?contains(FunctionName, `rearc`) || contains(FunctionName, `RearcDataQuest`)].FunctionName' --output table >> deployment-report.md
          echo "## SQS Queues:" >> deployment-report.md
          aws sqs list-queues --query 'QueueUrls[?contains(@, `rearc`) || contains(@, `RearcDataQuest`)]' --output table >> deployment-report.md

      - name: Upload Deployment Report
        uses: actions/upload-artifact@v4
        with:
          name: deployment-report
          path: deployment-report.md

  cleanup-on-failure:
    name: Cleanup on Failure
    runs-on: ubuntu-latest
    needs: [deploy-infrastructure, deploy-applications, integration-tests]
    if: failure() && (github.ref == 'refs/heads/main' || contains(github.ref, 'cursor/') || github.event_name == 'workflow_dispatch')
    environment: 
      name: ${{ github.event.inputs.environment || 'dev' }}

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ env.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}

      - name: Install AWS CDK
        run: |
          npm install -g aws-cdk@latest

      - name: Destroy CDK Stack (Optional)
        run: |
          cd part4_infrastructure/cdk
          echo "Deployment failed. To cleanup resources, run: cdk destroy --force"
          # Uncomment the next line if you want automatic cleanup on failure
          # cdk destroy --force
        continue-on-error: true

  trigger-e2e-pipeline:
    name: Trigger End-to-End Pipeline
    runs-on: ubuntu-latest
    needs: [deploy-infrastructure, deploy-applications, integration-tests]
    if: success() && github.event.inputs.trigger-e2e-pipeline == 'true'
    environment: 
      name: ${{ github.event.inputs.environment || 'dev' }}

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Trigger E2E Pipeline Workflow
        uses: actions/github-script@v7
        env:
          ENVIRONMENT: ${{ github.event.inputs.environment || 'dev' }}
          AWS_REGION: ${{ github.event.inputs.aws-region || 'us-east-2' }}
        with:
          script: |
            const response = await github.rest.actions.createWorkflowDispatch({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'e2e-pipeline.yml',
              ref: 'main',
              inputs: {
                environment: process.env.ENVIRONMENT,
                'aws-region': process.env.AWS_REGION,
                'skip-deployment': 'true',
                'data-validation-timeout': '15'
              }
            });
            
            console.log(`E2E Pipeline triggered with run ID: ${response.data}`);
            
            // Add a comment or summary
            const summary = `
            ## ðŸš€ End-to-End Pipeline Triggered
            
            The deployment completed successfully and the end-to-end pipeline has been triggered.
            
            **Environment**: ${process.env.ENVIRONMENT}
            **Region**: ${process.env.AWS_REGION}
            **Skip Deployment**: true (using existing infrastructure)
            
            Check the [Actions tab](${context.payload.repository.html_url}/actions) to monitor the E2E pipeline execution.
            `;
            
            await core.summary.addRaw(summary).write();